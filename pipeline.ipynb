{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Загружаем отобранные id моделей на яндекс маркете.\n",
    "\n",
    "###### вопрос отбора id моделей остается открытый, самы простой способ запросить через api топ популярных моделей на яндекс.маркете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"model_ids_2.txt\") as file:\n",
    "    model_ids = [row.strip() for row in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Класс для работы с Яднекс.маркет API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем класс для работы с API яндекс маркета\n",
    "первая функция генерирует запрос с учетом переданной модели\n",
    "вторая генерирует сам запрос и возвращает json ответ с отзывами, на вход получает id модели и набор параметром: количество отзывов на одной странице; номер страницы с отзывами; и т. д.,\n",
    "третья функция просто обертка для удобства."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "class YandexMarketContent(object):\n",
    "    \n",
    "  class NotAuthorized(BaseException):\n",
    "    pass\n",
    "\n",
    "  def __init__(self, key=None):\n",
    "    if not key:\n",
    "      raise YandexMarketContent.NotAuthorized(\"You must provide authorization key to access Yandex.Market API!\")\n",
    "    self.key = key\n",
    "\n",
    "  def _make_opinions_url(self, model, format='json'):\n",
    "    return 'https://api.content.market.yandex.ru/v2/models/'+ model +'/opinions/'\n",
    "\n",
    "  def _make_request(self, model, params):\n",
    "    url = self._make_opinions_url(model)\n",
    "    query_params = params\n",
    "    params['Authorization'] = self.key\n",
    "\n",
    "    response = requests.get(url, params=params, headers={'Authorization':self.key, 'Accept':'*/*'})\n",
    "    output = json.loads(response.content)\n",
    "    if response.status_code == 401:\n",
    "      server_response = []\n",
    "      for error in output['errors']:\n",
    "        server_response.append(error)\n",
    "      raise YandexMarketContent.NotAuthorized(\"Your key `%s' wasn't authorized at Yandex.Market API. Server response: %s\" % (self.key, server_response))\n",
    "\n",
    "    return output\n",
    "\n",
    "  def req(self, model, params):\n",
    "    columns = ['opinion','grade']\n",
    "    df_temp = pd.DataFrame(columns=columns)\n",
    "    response = self._make_request(model, params)\n",
    "    for i in range(0,30):\n",
    "        op = ''\n",
    "        grade = ''\n",
    "        if ('opinions' in response):\n",
    "            if  ('cons' in response['opinions'][i]):\n",
    "                op += response['opinions'][i]['cons'] + \" \"\n",
    "            if ('pros' in response['opinions'][i]):\n",
    "                 op += response['opinions'][i]['pros'] + \" \"\n",
    "            if ('text' in response['opinions'][i]):\n",
    "                 op += response['opinions'][i]['text']\n",
    "        else:\n",
    "            continue\n",
    "        grade = response['opinions'][i]['grade']\n",
    "        df_temp = df_temp.append({'opinion': op, 'grade': grade}, ignore_index=True)\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нас интересуют поля cons, pros, text и grade\n",
    "из полей cons, pros и text формируем отзыв, а grade - оценка по пятибальной шкале"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формирование dataset'a отзывов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "создаем объект с полученным api ключом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "api = YandexMarketContent(key='8e85dd1c-4bc5-45ec-a877-5932f0246826')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проходим по трем страницам отзывов каждой модели, на каждой странице 30 отзывов\n",
    "Получаем по 90 отзывов на каждый id модели и сохраняем их в массив для дальнейшей обработки\n",
    "\n",
    "###### Чтобы не превышать лимит Яндекса в 10 запросов в секунду, сделаем таймер по одному запросу каждую секунду"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['opinion','grade']\n",
    "df = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.45 s, sys: 79 ms, total: 3.53 s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "for i in range(1,2):\n",
    "    for model in model_ids:\n",
    "        df = df.append(api.req(model, params={'count':30, 'page':i}), ignore_index=True)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Посмотрим размер получившегося массива"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4830"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним получившейся набор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('data_op.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем данные из файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('data_op.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " все оценки 4 и 5 делаем положительными (1) \n",
    "оценки 3,2,1 - отрицательные (0) \n",
    "и удаляем все лишние столбцы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['grade'] < 4, 'grade'] = 0\n",
    "df.loc[df['grade'] > 3, 'grade'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь приступаем к работе с датафреймом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opinion</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Нет NFC\\n2. Даже 32 ГБ внутренней памяти эт...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Расположение датчика отпечатка пальца Батарея,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>- сяоми забросили эту модель и присылают тольк...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Камера оставляет желать лучшего.\\n По соотноше...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Автономность через год активного использования...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             opinion grade\n",
       "0  1. Нет NFC\\n2. Даже 32 ГБ внутренней памяти эт...     1\n",
       "1  Расположение датчика отпечатка пальца Батарея,...     1\n",
       "2  - сяоми забросили эту модель и присылают тольк...     1\n",
       "3  Камера оставляет желать лучшего.\\n По соотноше...     1\n",
       "4  Автономность через год активного использования...     1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4830 entries, 0 to 4829\n",
      "Data columns (total 2 columns):\n",
      "opinion    4830 non-null object\n",
      "grade      4830 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 75.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "посмотрим разделение по классам, как видно отрицательных отзывов почти в два раза меньше положительных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opinion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       opinion\n",
       "grade         \n",
       "0         1658\n",
       "1         3172"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['grade']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим данные для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['opinion'].values\n",
    "y = df['grade']\n",
    "y=y.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестируем модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "попробуем \"в лоб\" линейные модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8103462275339588\n",
      "Score std:  0.014237645897366927\n"
     ]
    }
   ],
   "source": [
    "model = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('lr', LogisticRegression()),\n",
    "])\n",
    "score = cross_val_score(model, X, y, cv=5)\n",
    "print('Accuracy: ', score.mean())\n",
    "print('Score std: ', score.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность: 0.8103462275339588"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score mean:  0.8031032755116152\n",
      "Score std:  0.006596645293570202\n"
     ]
    }
   ],
   "source": [
    "model_2 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('lr', LogisticRegression()),\n",
    "])\n",
    "score_2 = cross_val_score(model_2, X, y, cv=5)\n",
    "print('Score mean: ', score_2.mean())\n",
    "print('Score std: ', score_2.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность: 0.8031032755116152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score mean:  0.8033094553237229\n",
      "Score std:  0.01799713670299746\n"
     ]
    }
   ],
   "source": [
    "model_3 = Pipeline([\n",
    "    ('vect', CountVectorizer(min_df=10)),\n",
    "    ('lr', LogisticRegression()),\n",
    "])\n",
    "score_3 = cross_val_score(model_3, X, y, cv=5)\n",
    "print('Score mean: ', score_3.mean())\n",
    "print('Score std: ', score_3.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность: 0.8033094553237229"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score mean:  0.7697594115503857\n",
      "Score std:  0.01895462929628957\n"
     ]
    }
   ],
   "source": [
    "model_4 = Pipeline([\n",
    "    ('vect', CountVectorizer(min_df=50)),\n",
    "    ('lr', LogisticRegression()),\n",
    "])\n",
    "score_4 = cross_val_score(model_4, X, y, cv=5)\n",
    "print('Score mean: ', score_4.mean())\n",
    "print('Score std: ', score_4.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность: 0.7697594115503857"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score mean:  0.7881831403167506\n",
      "Score std:  0.025756548582510863\n"
     ]
    }
   ],
   "source": [
    "model_5 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('LSVC', LinearSVC()),\n",
    "])\n",
    "score_5 = cross_val_score(model_5, X, y, cv=5)\n",
    "print('Score mean: ', score_5.mean())\n",
    "print('Score std: ', score_5.std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность: 0.7881831403167506"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score mean:  0.7830137976784894\n",
      "Score std:  0.016387130134625713\n"
     ]
    }
   ],
   "source": [
    "model_6 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('SGD', SGDClassifier()),\n",
    "])\n",
    "score_6 = cross_val_score(model_6, X, y, cv=5)\n",
    "print('Score mean: ', score_6.mean())\n",
    "print('Score std: ', score_6.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность: 0.7830137976784894"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем с n-граммами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with bigrams:  0.8178043646383056\n"
     ]
    }
   ],
   "source": [
    "model_7 = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(1,2))),\n",
    "    ('lr', LogisticRegression()),\n",
    "])\n",
    "score_7 = cross_val_score(model_7, X, y, cv=5)\n",
    "print('Accuracy with bigrams: ', score_7.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность: 0.8178043646383056"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with bigrams:  0.814077868006124\n"
     ]
    }
   ],
   "source": [
    "model_8 = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(1,3))),\n",
    "    ('lr', LogisticRegression()),\n",
    "])\n",
    "score_8 = cross_val_score(model_8, X, y, cv=5)\n",
    "print('Accuracy with bigrams: ', score_8.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность: 0.814077868006124"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## GridSearch для формирования финальной модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "выберем из двух наиболее точных пайплайнов с помощью gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('vectorizer', CountVectorizer()), ('classifier', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'classifier': [LogisticRegression(), SGDClassifier()], \n",
    "    'vectorizer': [CountVectorizer(), TfidfVectorizer()],\n",
    "    'vectorizer__min_df': [1, 2, 10, 50],\n",
    "    'vectorizer__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'vectorizer__analyzer':['word', 'char_wb']},\n",
    "    {'classifier': [LogisticRegression(), SGDClassifier()], \n",
    "    'vectorizer': [CountVectorizer(), TfidfVectorizer()],\n",
    "    'vectorizer__min_df': [1, 2, 10, 50],\n",
    "    'vectorizer__ngram_range': [(3,5)],\n",
    "    'vectorizer__analyzer':['char_wb']}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False), 'vectorizer': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None), 'vectorizer__analyzer': 'word', 'vectorizer__min_df': 1, 'vectorizer__ngram_range': (1, 2)}\n",
      "CPU times: user 6.8 s, sys: 1.17 s, total: 7.97 s\n",
      "Wall time: 16min 18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid.fit(X, y)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8372670807453416\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучший результат у SGDClassifier + TfidfVectorizer с биграммами\n",
    "##### Точность: 0.8372670807453416"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем подобрать альфа у классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'classifier': [SGDClassifier(class_weight='balanced')], \n",
    "    'vectorizer': [TfidfVectorizer(ngram_range=(1,2))],\n",
    "    'classifier__alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False), 'classifier__alpha': 0.0001, 'vectorizer': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)}\n",
      "CPU times: user 2.42 s, sys: 74.3 ms, total: 2.49 s\n",
      "Wall time: 27.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid.fit(X, y)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8360248447204969\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "получились стандартные параметры и такая же точность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохраняем для дальнейшего использования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохрним модель для дальнейшего использования в веб прототипе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',\n",
    "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
    "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
    "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
    "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
    "       validation_fraction=0.1, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='word', binary=False, decode_error='strict', encoding='utf-8', input='content',\n",
    "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
    "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
    "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
    "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
    "        vocabulary=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train =vectorizer.fit_transform(X) \n",
    "model.fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as cPickle\n",
    "# save the classifier\n",
    "with open('SGD.pkl', 'wb') as fid:\n",
    "    cPickle.dump(model, fid)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Tfidf.pkl', 'wb') as fid:\n",
    "    cPickle.dump(vectorizer, fid)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказываем и записываем в файл"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбираем файл с тестовым набором"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('test.csv', 'rU') as f:\n",
    "    data = f.read()\n",
    "test_op = [r.text for r in bs4.BeautifulSoup(data, 'lxml').find_all('review')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказываем значения и записываем в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = pd.DataFrame(grid.predict(test_op), columns=['y'])\n",
    "out.index.name = 'Id'\n",
    "out['y'] = out['y'].apply(lambda x: 'neg' if (x==0) else 'pos')\n",
    "out.to_csv('subm.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
